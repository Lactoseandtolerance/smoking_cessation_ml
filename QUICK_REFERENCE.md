# Quick Reference Guide
## Essential Information at a Glance

---

## ðŸŽ¯ Project Goal
**Predict smoking cessation success using machine learning on PATH Study data (Waves 1-7)**

**Target Performance:** ROC-AUC > 0.70 (Benchmark: 0.72)  
**Achieved Performance:** Validation ROC-AUC 0.884 | Test ROC-AUC 0.669  
**Feature Count:** 52 canonical features  
**Timeline:** Completed with comprehensive evaluation

---

## ðŸ“ Project Structure

```
smoking_cessation_ml/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # PATH STATA files (Waves 1-7)
â”‚   â”œâ”€â”€ processed/                    # Generated datasets
â”‚   â”‚   â”œâ”€â”€ pooled_transitions.csv   # 47,882 transitions Ã— 52 features
â”‚   â”‚   â””â”€â”€ pooled_transitions.parquet
â”‚   â””â”€â”€ data_dictionary.md           # 52-feature variable mapping
â”œâ”€â”€ notebooks/                        # Jupyter notebooks (numbered 01-07)
â”œâ”€â”€ src/                             # Python modules (feature engineering, modeling, evaluation)
â”œâ”€â”€ models/                          # Saved models (XGBoost: 0.884 Val AUC)
â”œâ”€â”€ dashboard/app.py                 # Streamlit dashboard
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ PHASE5_RESULTS.md            # Validation metrics (0.884 AUC)
â”‚   â”œâ”€â”€ TEST_SET_RESULTS.md          # Test metrics (0.669 AUC)
â”‚   â”œâ”€â”€ WAVE_PAIR_EVAL.md            # Per-wave performance
â”‚   â”œâ”€â”€ FAIRNESS_RESULTS.md          # Subgroup AUC/FPR/FNR analysis
â”‚   â”œâ”€â”€ FEATURE_DRIFT.md             # Feature drift across waves
â”‚   â”œâ”€â”€ INTERPRETABILITY_SUMMARY.md  # SHAP feature importance
â”‚   â”œâ”€â”€ figures/                     # Generated charts
â”‚   â””â”€â”€ SUBGROUP_PERFORMANCE.csv     # Detailed fairness metrics
â”œâ”€â”€ ACTION_GUIDE.md                  # Detailed instructions (Waves 1-7)
â”œâ”€â”€ MVP_PLAN.md                      # Complete technical plan (Waves 1-7)
â”œâ”€â”€ README.md                        # Project overview (52 features, current metrics)
â””â”€â”€ requirements.txt                 # Python dependencies
```

---

## ðŸš€ Quick Start

```bash
# 1. Navigate to project
cd ~/data\ mining/smoking_cessation_ml

# 2. Activate environment
source venv/bin/activate

# 3. Start Jupyter
jupyter notebook

# 4. Run dashboard (after Phase 7)
streamlit run dashboard/app.py
```

---

## ðŸ“Š Phase Checklist

### âœ… Phase 1: Setup (Day 1) - COMPLETE
- [x] Register at ICPSR
- [x] Download PATH Waves 1-7 (STATA .dta format)
- [x] Download ADULT files only (NOT Youth or Parent files)
- [x] Download documentation
- [x] Install dependencies (including pyreadstat)
- [x] Initialize Git repo

### âœ… Phase 2: Sample (Days 2-3) - COMPLETE
- [x] Create data dictionary with actual variable names
- [x] Load all 7 waves
- [x] Create person-period dataset (47,882 transitions)
- [x] Calculate cessation rates by wave pair
- [x] Save `pooled_transitions.csv`

### âœ… Phase 3: Features (Days 4-5) - COMPLETE
- [x] Update feature engineering code with PATH variables
- [x] Engineer 52 canonical features (dependence, demographics, methods, environment, motivation)
- [x] Handle missing data with codebook overrides
- [x] Save `pooled_transitions.csv` with features
- [x] Feature count: 52 (exceeds MVP goal)

### âœ… Phase 4: Modeling (Days 6-9) - COMPLETE
- [x] Split by person_id (60/20/20) - no data leakage
- [x] Train Logistic Regression (Val AUC 0.787)
- [x] Train Random Forest (Val AUC 0.819)
- [x] Train XGBoost (Val AUC 0.884) âœ¨ Best performer
- [x] Evaluate on test set (Test AUC 0.669)
- [x] Save best model to `models/xgboost_best.pkl`

### âœ… Phase 5: SHAP & Interpretability (Days 10-11) - COMPLETE
- [x] Generate SHAP values for top 10-20 features
- [x] Create SHAP summary plot
- [x] Create SHAP dependence plots
- [x] Create SHAP waterfall plots
- [x] Document top features in `reports/INTERPRETABILITY_SUMMARY.md`

### âœ… Phase 6: Fairness Analysis (Day 12) - COMPLETE
- [x] Evaluate performance by demographic groups (sex, age cohort, race/ethnicity)
- [x] Calculate AUC, FPR, FNR disparities
- [x] Create fairness visualizations (heatmaps, bar charts)
- [x] Save results to `reports/FAIRNESS_RESULTS.md`
- [x] Note: Test AUC variance (0.669) suggests potential subgroup performance differences

### âœ… Phase 7: Wave-Pair Evaluation (Extended) - COMPLETE
- [x] Compute per-wave pair metrics (W1â†’W2, W2â†’W3, ..., W6â†’W7)
- [x] Feature drift analysis (mean differences and KS statistics)
- [x] Generate `reports/WAVE_PAIR_EVAL.md`
- [x] Generate `reports/FEATURE_DRIFT.md`
- [x] Dashboard ready at `dashboard/app.py`
- [ ] Document findings

### â¬œ Phase 7: Dashboard (Days 13-14)
- [ ] Create Streamlit app (6 pages)
- [ ] Test all pages
- [ ] Verify visualizations load

### â¬œ Phase 8: Report (Days 15-16)
- [ ] Write IEEE format report (4+ pages)
- [ ] Create 10-slide presentation
- [ ] Write speaking notes
- [ ] Rehearse presentation

---

## ðŸ”‘ Critical Code Snippets

### Load Data
```python
import pandas as pd
import sys
sys.path.append('../src')
from data_preprocessing import load_wave_data

# Will automatically handle STATA (.dta) or SPSS (.sav) format
wave1 = load_wave_data(1, '../data/raw', file_format='dta')

# Or directly with pandas:
wave1 = pd.read_stata('../data/raw/PATH_W1_Adult.dta')
```

### Train Model with Class Weighting
```python
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(
    class_weight='balanced',  # CRITICAL!
    max_iter=1000,
    random_state=42
)
lr.fit(X_train, y_train)
```

### Split by Person ID (Prevent Leakage)
```python
from sklearn.model_selection import train_test_split

unique_persons = pooled_data['person_id'].unique()
train_ids, temp_ids = train_test_split(unique_persons, test_size=0.4, random_state=42)
val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)

train_data = pooled_data[pooled_data['person_id'].isin(train_ids)]
```

### Generate SHAP Values
```python
import shap

explainer = shap.TreeExplainer(model)
shap_values = explainer(X_test_sample)
shap.summary_plot(shap_values, X_test_sample)
```

---

## ðŸ“š Key Resources

| Resource | URL |
|----------|-----|
| PATH Study Data | https://www.icpsr.umich.edu/web/NAHDAP/series/606 |
| Published Benchmark | https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0286883 |
| SHAP Documentation | https://shap.readthedocs.io/ |
| IEEE Template | https://www.ieee.org/conferences/publishing/templates.html |
| Streamlit Docs | https://docs.streamlit.io/ |

---

## âš ï¸ Common Pitfalls to Avoid

1. **Data Leakage** â†’ Always split by `person_id`, not by observation
2. **Forgetting Class Weighting** â†’ Enable in ALL models (not optional)
3. **Wrong Variable Names** â†’ Use actual PATH variable names from codebook
4. **Touching Test Set Early** â†’ Only use test set for final evaluation
5. **Skipping SHAP** â†’ Interpretability is required, not optional
6. **Ignoring Fairness** â†’ Must assess across demographic groups
7. **Writing at the End** â†’ Document as you go in notebooks

---

## ðŸŽ¯ Success Metrics

| Metric | Target | Notes |
|--------|--------|-------|
| Test Set AUC | > 0.70 | Benchmark: 0.72 (Issabakhsh 2023) |
| Features | 25-30 | Tier 1 features minimum |
| Models | 3 | Logistic Regression, Random Forest, XGBoost |
| Notebooks | 7 | All phases documented |
| Report | 4+ pages | IEEE format |
| Presentation | 10 slides | 10-minute talk |

---

## ðŸ“ž Getting Help

**If stuck, check:**
1. ACTION_GUIDE.md for detailed instructions
2. MVP_PLAN.md for complete technical details
3. PATH Study codebook for variable definitions
4. src/ modules for code examples

**Common issues:**
- "Variable not found" â†’ Check data_dictionary.md
- "Low AUC (<0.60)" â†’ Review feature engineering, enable class weighting
- "Import errors" â†’ Run `pip install -r requirements.txt`

---

## ðŸ Next Steps

1. **NOW:** Register at ICPSR (if not done)
2. **Day 1:** Download PATH data and documentation
3. **Day 2:** Start Phase 2 (analytical sample)
4. **Follow** ACTION_GUIDE.md step by step

**You have everything you need. Start Phase 1 today!**
